{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/kal/TF_models/bin/sequence.py:275: RuntimeWarning: divide by zero encountered in log\n",
      "  self.seq = helper.softmax(np.log(dist))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'sequence' from '/home/kal/TF_models/bin/sequence.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a pipeline to process lots of TFs, \n",
    "#train regresion models of them, \n",
    "#and then do some post procesing\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('/home/kal/TF_models/bin/')\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1' # Must be before importing keras!\n",
    "import tf_memory_limit\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.models import load_model, Model, Input\n",
    "from keras.layers import Input, Lambda, Conv1D\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt \n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from scipy.integrate import trapz\n",
    "from tqdm import tqdm\n",
    "import ucscgenome\n",
    "import math\n",
    "import pandas as pd\n",
    "import time\n",
    "import pickle\n",
    "import importlib\n",
    "\n",
    "import sequence\n",
    "import train_TFmodel\n",
    "import eval_TFmodel\n",
    "import ctcfgen\n",
    "import seq_only_gen\n",
    "import train_seq_regression_convnet\n",
    "\n",
    "importlib.reload(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ZBTB33' 'CEBPB' 'CTCF' 'TAF1' 'GABPA' 'USF1' 'SP1' 'EGR1' 'FOXA1'\n",
      " 'RUNX3' 'MAZ' 'RAD21' 'SMC3' 'MAFF' 'MAFK' 'BHLHE40' 'FOSL2' 'JUND'\n",
      " 'E2F6' 'MAX' 'POLR2A' 'PAX5' 'PHF8' 'PML' 'YY1' 'SIN3AK20' 'E2F1'\n",
      " 'GTF2F1' 'ATF2' 'MYC' 'KDM5A' 'MXI1' 'POU2F2' 'KDM5B' 'TBP' 'IRF1'\n",
      " 'EP300' 'TAF7' 'ELK1' 'RFX5' 'TCF7L2' 'CHD2' 'FOXP2' 'ATF3' 'BRCA1'\n",
      " 'NFYA' 'RELA' 'NFYB' 'GRp20' 'REST' 'JUN' 'E2F4' 'SRF' 'ELF1' 'CREB1'\n",
      " 'ATF1' 'SIX5' 'USF2' 'FOS' 'TBL1XR1' 'ZNF143' 'SP2' 'EBF1' 'CTCFL'\n",
      " 'TEAD4' 'THAP1' 'ZEB1' 'ZNF263' 'PBX3' 'UBTF' 'CBX3' 'BCLAF1' 'NR2C2'\n",
      " 'RBBP5' 'GATA1' 'RCOR1' 'FOSL1' 'GATA2' 'TAL1' 'GATA3' 'TCF12' 'BCL3'\n",
      " 'NFATC1' 'MEF2A' 'MEF2C' 'CCNT2' 'BACH1' 'HDAC2' 'TCF3' 'ZNF274' 'STAT1'\n",
      " 'BATF' 'SPI1' 'HMGN3' 'SETDB1' 'ETS1' 'ZBTB7A' 'EZH2' 'JUNB' 'SP4'\n",
      " 'TFAP2A' 'TFAP2C' 'NR2F2' 'ESR1' 'SIN3A' 'TRIM28' 'HNF4G' 'RXRA' 'GTF3C2'\n",
      " 'SUZ12' 'CTBP2' 'NR3C1' 'SAP30' 'CHD1' 'KAP1' 'NANOG' 'STAT5A' 'HDAC1'\n",
      " 'ELK4' 'NRF1' 'STAT3' 'HNF4A' 'FOXA2' 'SMARCC1' 'SMARCB1' 'ESRRA' 'STAT2'\n",
      " 'MYBL2' 'NFIC' 'SREBP1' 'ARID3A' 'CEBPD' 'IRF4' 'BCL11A' 'MTA3' 'FOXM1'\n",
      " 'ZNF217' 'HSF1' 'HDAC8' 'NFE2' 'IRF3' 'WRNIP1' 'GTF2B' 'HDAC6' 'SMARCA4'\n",
      " 'ZKSCAN1' 'BRF2' 'IKZF1' 'POU5F1' 'RPC155' 'PPARGC1A' 'BDP1' 'SIRT6'\n",
      " 'SMARCC2' 'MBD4' 'PRDM1' 'FAM48A' 'RDBP' 'ZZZ3' 'POLR3G' 'BRF1']\n"
     ]
    }
   ],
   "source": [
    "# get a list of all the tf's I might use\n",
    "bed_path = '/home/kal/TF_models/data/encode_chipseq_peaks.bed'\n",
    "full = pd.read_table(bed_path, header=None)\n",
    "full.columns = 'chr start end name score expCount expNums expScores'.split()\n",
    "TFs = full.name.unique()\n",
    "print(TFs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "paths = dict()\n",
    "ml_models = dict()\n",
    "gens = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get the TF paths if already made\n",
    "for file in tqdm(os.listdir('/home/kal/TF_models/seq_only/seq_regression/')):\n",
    "    for TF in TFs:\n",
    "        if file.endswith(TF):\n",
    "            out_path = os.path.join('/home/kal/TF_models/seq_only/seq_regression/', file)\n",
    "            paths[TF] = out_path\n",
    "            gen_path = os.path.join(out_path, TF + '_gen.hdf5')\n",
    "            #gens[TF] = seq_only_gen.TFGenerator(gen_path)\n",
    "            #ml_models[TF] = eval_TFmodel.TFmodel(out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking at transcription factor: ZBTB33\n",
      "Makeing generator for ZBTB33\n",
      "Number of training examples: 12172\n",
      "Only 12172 training samples\n",
      "Looking at transcription factor: CEBPB\n",
      "Makeing generator for CEBPB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "717it [00:00, 7166.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 139771\n",
      "Building itrtree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "146873it [00:17, 8428.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing hdf5 File\n",
      "Finished positive training\n",
      "Finished positive testing\n",
      "Finished positive validation\n",
      "Finished negative training\n",
      "Finished negative testing\n",
      "Finished negative validation\n",
      "Wrote to file\n",
      "Training model for CEBPB\n",
      "Convolutions used: [[32, 3], [32, 32], [16, 3], [8, 3]] [neurons, filter]\n"
     ]
    }
   ],
   "source": [
    "# make a folder system and get a generator and model for each\n",
    "for TF in TFs:\n",
    "    # make the folders\n",
    "    print('Looking at transcription factor: ' + TF)\n",
    "    timestr = time.strftime(\"%Y%m%d_%H%M%S\")       \n",
    "    out_path = os.path.join('/home/kal/TF_models/seq_only/seq_regression/', timestr + '_' + TF)\n",
    "    paths[TF] = out_path\n",
    "    os.makedirs(out_path)\n",
    "    gen_path = os.path.join(out_path, TF + '_gen.hdf5')\n",
    "    # make the generator\n",
    "    print('Makeing generator for ' + TF)\n",
    "    try:\n",
    "        seq_only_gen.create_from_bed(bed_path, gen_path, TF=TF, example_limit = 25000)        \n",
    "        gens[TF] = seq_only_gen.TFGenerator(gen_path)\n",
    "        print('Training model for ' + TF)\n",
    "        # make and train the model\n",
    "        train_seq_regression_convnet.make_model(out_path, '32.3_32.32_16.3_8.3', gen_path)\n",
    "    except IndexError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# plot the training loss curves\n",
    "for TF in TFs:\n",
    "    print('Training for TF' + TF)\n",
    "    for file in os.listdir(os.path.join(paths[TF], 'history')):\n",
    "        file = os.path.join(os.path.join(paths[TF], 'history'), file)\n",
    "        # find the history pickles\n",
    "        if file.endswith('1.pk1'):\n",
    "            with open(file, 'rb') as infile:\n",
    "                h1 = pickle.load(infile)\n",
    "        elif file.endswith('2.pk1'):\n",
    "            with open(file, 'rb') as infile:\n",
    "                h2 = pickle.load(infile)\n",
    "        elif file.endswith('3.pk1'):\n",
    "            with open(file, 'rb') as infile:\n",
    "                h3 = pickle.load(infile)\n",
    "    # Summarize history for accuracy\n",
    "    plt.plot(eval_TFmodel.group_stats('loss', h1, h2, h3))\n",
    "    plt.plot(eval_TFmodel.group_stats('val_loss', h1, h2, h3))\n",
    "    plt.title('Training and Validation Loss for a model of ' + TF)\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# make a frozen weight model for each pwm\n",
    "pwm_models = dict()\n",
    "\n",
    "for file in tqdm(os.listdir('/home/kal/TF_models/data/memes')):\n",
    "    for TF in TFs:\n",
    "        file = os.path.join('/home/kal/TF_models/data/memes', file)\n",
    "        # find the meme file\n",
    "        if file.endswith(TF + '.meme'):\n",
    "            print('Making a pwm model for TF ' +  TF)\n",
    "            pwm_model_path = os.path.join(paths[TF], TF + '_frozen.hdf5')\n",
    "            print(file)\n",
    "            # construct the frozen weight model\n",
    "            weights = sequence.process_meme(file)[0].pwm\n",
    "            weights = np.expand_dims(weights, axis=2)\n",
    "            input = Input(batch_shape=(32, 256, 4))\n",
    "            add_RC_to_batch = Lambda(lambda x: K.concatenate([x, x[:, ::-1, ::-1]], axis=0), output_shape=lambda s: (2 * s[0], s[1], s[2]))\n",
    "            # convolution for the motif\n",
    "            pwm_conv = Conv1D(1, weights.shape[0], padding='valid', input_shape=(256,4), weights=[weights, np.asarray([0])])\n",
    "            pwm_conv.trainable = False\n",
    "            max_by_direction = Lambda(lambda x: K.maximum(K.max(x[:x.shape[0]//2, :, :], axis=1), K.max(x[x.shape[0]//2:, ::-1, :], axis=1)), name='stackmax', output_shape=lambda s: (s[0] // 2, 1))\n",
    "            predictions = max_by_direction(pwm_conv(add_RC_to_batch(input)))\n",
    "            model = Model(inputs=[input], outputs=[predictions])\n",
    "            # compile the network\n",
    "            #optimizer = Adam(beta_1=0.95, lr=0.0005, epsilon=.1)\n",
    "            #model.compile(loss='mean_squared_error', optimizer=optimizer, metrics=['mse'])\n",
    "            #save the network\n",
    "            model.save(pwm_model_path)\n",
    "            # add the model to the dictionary    \n",
    "            pwm_models[TF] = eval_TFmodel.TFmodel(paths[TF], model_path = pwm_model_path)\n",
    "            print('Made the model!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# compare each pwm and deep learning model on the test dataset (atac later?)\n",
    "# predict on test sequences and make a p-r and p-r gain curve\n",
    "test_precision = dict()\n",
    "test_recall = dict()\n",
    "\n",
    "missing_memes = list()\n",
    "for TF in TFs:\n",
    "    try:\n",
    "        print('Making a PR curve for ' + TF)\n",
    "        g = gens[TF].pair_gen(mode='val')\n",
    "        true_labels = list()\n",
    "        reg_preds = list()\n",
    "        pwm_preds = list()\n",
    "        for i in tqdm(range(1000)):\n",
    "            batch, labels = next(g)\n",
    "            true_labels.append(labels)\n",
    "            reg_preds.append(ml_models[TF].model.predict(batch))\n",
    "            pwm_preds.append(pwm_models[TF].model.predict(batch))   \n",
    "        true_labels = np.asarray(true_labels).flatten().tolist()\n",
    "        reg_preds = np.asarray(reg_preds).flatten().tolist()\n",
    "        pwm_preds = np.asarray(pwm_preds).flatten().tolist()\n",
    "    \n",
    "        #p-r curve\n",
    "        pwm_p, pwm_r, pwm_t = precision_recall_curve(true_labels, pwm_preds, pos_label=1)\n",
    "        reg_p, reg_r, reg_t = precision_recall_curve(true_labels, reg_preds, pos_label=1)\n",
    "    \n",
    "        #save the values\n",
    "        test_precision[TF] = reg_p\n",
    "        test_recall[TF] = reg_r\n",
    "        test_precision[TF + '_PWM'] = pwm_p\n",
    "        test_recall[TF + '_PWM'] = pwm_r\n",
    "\n",
    "        plt.figure(figsize=(8,6))\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.title('P-R Curve for ' + TF + ' Binding via ENCODE dataset')\n",
    "        plt.xlabel('Recall')\n",
    "        plt.ylabel('Precision')\n",
    "        plt.plot(reg_r, reg_p, label='Regression Model')\n",
    "        plt.plot(pwm_r, pwm_p, label='PWM Model')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    \n",
    "        #p-r gain gurve\n",
    "        # we consider only p/r value between prop_pos and 1\n",
    "        prop_pos = sum(true_labels)/len(true_labels)\n",
    "        reg_pgain = [(x-prop_pos)/((1-prop_pos)*x) for x in reg_p]\n",
    "        reg_rgain = [(x-prop_pos)/((1-prop_pos)*x) for x in reg_r]\n",
    "        pwm_pgain = [(x-prop_pos)/((1-prop_pos)*x) for x in pwm_p]\n",
    "        pwm_rgain = [(x-prop_pos)/((1-prop_pos)*x) for x in pwm_r]\n",
    "\n",
    "        plt.figure(figsize=(8,6))\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.title('P-R Gain Curve for CTCF Binding via ENCODE dataset')\n",
    "        plt.xlabel('Recall Gain')\n",
    "        plt.ylabel('Precision Gain')\n",
    "        plt.plot(pwm_rgain, pwm_pgain, label='PWM Model')\n",
    "        plt.plot(reg_rgain, reg_pgain, label='Regression Model')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    except KeyError:\n",
    "        print('Woops no pwm model.')\n",
    "        missing_memes.append(TF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "AOC = dict()\n",
    "for TF in ['CTCF']:\n",
    "    # get aoc numbers!\n",
    "    AOC[TF] = - trapz(test_precision[TF], test_recall[TF])\n",
    "    AOC[TF + '_PWM'] = - trapz(test_precision[TF + '_PWM'], test_recall[TF + '_PWM'])\n",
    "\n",
    "print(AOC['CTCF'])\n",
    "print(AOC['CTCF_PWM'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pair = gen.pair_gen(strengths=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
