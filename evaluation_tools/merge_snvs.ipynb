{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import subprocess\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# concatenate all the bed files\n",
    "# get normalization vlues for each bed file\n",
    "first = True\n",
    "norms = dict()\n",
    "for file in os.listdir('/home/thouis/CTCF_variants/allele_counts'):\n",
    "    temp = pd.read_table(os.path.join('/home/thouis/CTCF_variants/allele_counts', file))\n",
    "    temp.columns = 'chr start variantID refAllele altAllele refCount altCount totalCount lowMAPQDepth lowBaseQDepth rawDepth otherBases improperPairs'.split()\n",
    "    temp['norm'] = sum(temp['totalCount'])/len(temp['totalCount'])\n",
    "    if first:\n",
    "        snvs = temp\n",
    "        first = False\n",
    "    else:\n",
    "        snvs = snvs.append(temp)\n",
    "        \n",
    "plt.hist(snvs['norm'])\n",
    "plt.title('Normalization Values for SNP reads from Different Experiments')\n",
    "plt.ylabel('Number of Experiments')\n",
    "plt.xlabel('Average Counts per Site')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# add an 'end' column\n",
    "snvs['end'] = snvs.start + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# write out one masive file\n",
    "header = ['chr', 'start', 'end', 'refAllele',  'altAllele',  'refCount',  'altCount', 'norm']\n",
    "snvs.to_csv('/home/kal/TF_models/data/SNVs/thouis_snvs/all_snvs.bed', sep='\\t', columns = header, header=None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# sort that file\n",
    "command = ['sort', '-k1,1', '-k2,2n', '/home/kal/TF_models/data/SNVs/thouis_snvs/all_snvs.bed']\n",
    "result = subprocess.run(command, stdout=open('/home/kal/TF_models/data/SNVs/thouis_snvs/all_snvs_sorted.bed', 'w'), stderr=subprocess.PIPE, universal_newlines=True)\n",
    "print(result.returncode, result.stdout, result.stderr)\n",
    "\n",
    "# merge the features\n",
    "# bedtools merge -d -1 -c 4,5,6,7 -o distinct,distinct,sum,sum -i all_snvs_sorted.bed > all_snvs_merged.bed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# gauge the dataset with some filters\n",
    "print(len(snvs))\n",
    "bins = np.linspace(0, 100, 50)\n",
    "plt.hist(snvs['totalCount'], bins, alpha=0.5)\n",
    "plt.hist(snvs['altCount'], bins, alpha=0.5)\n",
    "plt.hist(snvs['refCount'], bins, alpha=0.5)\n",
    "plt.legend(['Total Count', 'Alternate Count', 'Reference Count'])\n",
    "plt.title('Distribution of Counts')\n",
    "plt.ylabel('Number of Experiments')\n",
    "plt.xlabel('Counts')\n",
    "plt.show()\n",
    "\n",
    "# gauge the dataset with some filters\n",
    "cutoff=5\n",
    "bothoff=10\n",
    "filtered = snvs[(((snvs['altCount']>cutoff) & (snvs['refCount']>cutoff)) & (snvs['totalCount']>bothoff))]\n",
    "print(len(filtered))\n",
    "bins = np.linspace(0, 100, 50)\n",
    "plt.hist(filtered['totalCount'], bins, alpha=0.5)\n",
    "plt.hist(filtered['altCount'], bins, alpha=0.5)\n",
    "plt.hist(filtered['refCount'], bins, alpha=0.5)\n",
    "plt.legend(['Total Count', 'Alternate Count', 'Reference Count'])\n",
    "plt.title('Distribution of Counts with (5, 10) filter')\n",
    "plt.ylabel('Number of Experiments')\n",
    "plt.xlabel('Counts')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get the sorted file\n",
    "snps = pd.read_table('/home/kal/TF_models/data/SNVs/thouis_snvs/all_snvs_sorted.bed', header=None)\n",
    "snps.columns = ['chr', 'start', 'end', 'refAllele',  'altAllele',  'refCount',  'altCount', 'norm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2294484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2294484it [03:27, 11054.25it/s]\n"
     ]
    }
   ],
   "source": [
    "# merege the features but better\n",
    "# only if > 5 reads on alternate allele for every individual experiment and the snp is the same\n",
    "# HETEROZYGOUS only\n",
    "ref_row = snps.iloc[0]\n",
    "allele_to_n = {'a':0, 'c':1, 't':2, 'g':3}\n",
    "n_to_allele = ['a', 'c', 't', 'g']\n",
    "count = [0,0,0,0]\n",
    "filtered_snps = list()\n",
    "def update_count(count, row):\n",
    "    # generate array from row\n",
    "    # but with thresholding\n",
    "    # and normalization\n",
    "    if (int(row.refCount) > 5) and (int(row.altCount) > 5):\n",
    "        count[allele_to_n[row.refAllele.lower()]] += int(row.refCount)/row.norm\n",
    "        count[allele_to_n[row.altAllele.lower()]] += int(row.altCount)/row.norm\n",
    "    return count\n",
    "    \n",
    "#cycle through\n",
    "print(len(snps))\n",
    "for index, row in tqdm(snps.iterrows()):\n",
    "    # at same position?\n",
    "    if ref_row.start == int(row.start) and ref_row.chr == row.chr:\n",
    "        update_count(count, row)\n",
    "    else:\n",
    "        # write out the last bit of data\n",
    "        for allele in n_to_allele:\n",
    "            if ref_row['refAllele'].lower() == allele:\n",
    "                pass\n",
    "            elif count[allele_to_n[allele]] > 0:\n",
    "                # make a new row for each nonzero elem\n",
    "                ref_count = count[allele_to_n[ref_row.refAllele.lower()]]\n",
    "                alt_count = count[allele_to_n[allele]]\n",
    "                new_row = [ref_row.chr, ref_row.start, ref_row.end, ref_row.refAllele.lower(), allele, ref_count, alt_count]\n",
    "                filtered_snps.append(new_row)\n",
    "        # start for the next row\n",
    "        ref_row = row\n",
    "        count = [0, 0, 0, 0]\n",
    "        update_count(count, row)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "columns=['chr', 'start', 'end', 'refAllele',  'altAllele',  'refCount',  'altCount']\n",
    "filtered = pd.DataFrame(filtered_snps, columns=columns)\n",
    "# write out one masive file\n",
    "filtered.to_csv('/home/kal/TF_models/data/SNVs/thouis_snvs/snvs_5filtered_merge.bed', sep='\\t', columns = columns, header=None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2294484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2294484it [04:42, 8128.77it/s]\n"
     ]
    }
   ],
   "source": [
    "# merege the features but better\n",
    "# only if > 5 reads on each allele after all experiments summed and the snp is the same\n",
    "# HETEROZYGOUS + HOMOZYGOUS\n",
    "ref_row = snps.iloc[0]\n",
    "allele_to_n = {'a':0, 'c':1, 't':2, 'g':3}\n",
    "n_to_allele = ['a', 'c', 't', 'g']\n",
    "count = [0,0,0,0]\n",
    "filtered_snps = list()\n",
    "def update_count(count, row):\n",
    "    # generate array from row\n",
    "    # with normalization (threshlding later)\n",
    "    count[allele_to_n[row.refAllele.lower()]] += int(row.refCount)/row.norm\n",
    "    count[allele_to_n[row.altAllele.lower()]] += int(row.altCount)/row.norm\n",
    "    return count\n",
    "    \n",
    "#cycle through\n",
    "print(len(snps))\n",
    "for index, row in tqdm(snps.iterrows()):\n",
    "    # at same position?\n",
    "    if ref_row.start == int(row.start) and ref_row.chr == row.chr:\n",
    "        update_count(count, row)\n",
    "    else:\n",
    "        # write out the last bit of data\n",
    "        for allele in n_to_allele:\n",
    "            if ref_row['refAllele'].lower() == allele:\n",
    "                pass\n",
    "            elif (count[allele_to_n[allele]] > 1) and (count[allele_to_n[ref_row['refAllele'].lower()]] > 1):\n",
    "                # make a new row for each elem with normalized read density > 1 (after summing over experiemnts)\n",
    "                ref_count = count[allele_to_n[ref_row.refAllele.lower()]]\n",
    "                alt_count = count[allele_to_n[allele]]\n",
    "                new_row = [ref_row.chr, ref_row.start, ref_row.end, ref_row.refAllele.lower(), allele, ref_count, alt_count]\n",
    "                filtered_snps.append(new_row)\n",
    "        # start for the next row\n",
    "        ref_row = row\n",
    "        count = [0, 0, 0, 0]\n",
    "        update_count(count, row)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns=['chr', 'start', 'end', 'refAllele',  'altAllele',  'refCount',  'altCount']\n",
    "filtered = pd.DataFrame(filtered_snps, columns=columns)\n",
    "# write out one masive file\n",
    "filtered.to_csv('/home/kal/TF_models/data/SNVs/thouis_snvs/snvs_1homofiltered_merge.bed', sep='\\t', columns = columns, header=None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
