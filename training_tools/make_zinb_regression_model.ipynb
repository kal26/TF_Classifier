{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Make a model that predicts 9 channels of log rc \n",
    "    using zinb loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('/home/kal/TF_models/bin/')\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2' # Must be before importing keras!\n",
    "import tf_memory_limit\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard, Callback, LearningRateScheduler\n",
    "from keras.utils import plot_model\n",
    "from keras.layers import Input, Lambda, Dense, Conv1D, Activation\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt \n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from scipy.integrate import trapz\n",
    "from tqdm import tqdm\n",
    "import ucscgenome\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "import sequence\n",
    "import train_TFmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# set up directories\n",
    "out_path = os.path.join('/home/kal/TF_models/seq_only/count_regression/zinb_CTCF')\n",
    "os.makedirs(out_path)\n",
    "weights_path = os.path.join(out_path, 'intermediate_weights')\n",
    "os.makedirs(weights_path)\n",
    "history_path = os.path.join(out_path, 'history')\n",
    "os.makedirs(history_path)\n",
    "\n",
    "#load in data\n",
    "bed_path = '/home/kal/TF_models/data/count_regression/ctcf_regions_9_seqs.bed'\n",
    "columns='chr start end name score nucs c1 c2 c3 c4 c5 c6 c7 c8 c9'\n",
    "score_columns ='c1 c2 c3 c4 c5 c6 c7 c8 c9'.split()\n",
    "peaks = pd.read_table(bed_path, header=None)\n",
    "peaks.columns = columns.split()\n",
    "\n",
    "# macro variables\n",
    "prediction_window = 256\n",
    "half_window = prediction_window // 2\n",
    "num_training_examples = sum(peaks.chr != 'chr8')\n",
    "batch_size = 32\n",
    "drop_rate = 0.1\n",
    "conv_string='32.3_32.32_32.3_16.3'\n",
    "conv_list = [[int(x) for x in cell.split('.')] for cell in conv_string.split('_')]\n",
    "num_outputs = len(score_columns)\n",
    "num_epochs=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def native_gen(mode='train', once=False):\n",
    "    \"\"\"Generate a positive seqeunce sample.\"\"\"\n",
    "    done = False\n",
    "    if mode == 'test':\n",
    "        indices = np.asarray(peaks[peaks.chr == 'chr8'].index.values)\n",
    "        indices = [x for x in indices if x%2 == 0]\n",
    "    elif mode =='val':\n",
    "        indices = np.asarray(peaks[peaks.chr == 'chr8'].index.values)\n",
    "        indices = [x for x in indices if x%2 == 1]\n",
    "    else:\n",
    "        indices = np.asarray(peaks[peaks.chr != 'chr8'].index.values)\n",
    "    while not done:\n",
    "        np.random.shuffle(indices)\n",
    "        for idx in indices:\n",
    "            if len(score_columns) == 1:\n",
    "                yield peaks.get_value(idx, 'nucs'), peaks.get_value(idx, score_columns)\n",
    "            else:\n",
    "                scores=list()\n",
    "                for c in score_columns:\n",
    "                    scores.append(peaks.get_value(idx, c))\n",
    "                yield peaks.get_value(idx, 'nucs'), np.asarray(scores)\n",
    "            done = once\n",
    "            \n",
    "def scrambled_gen(scrambled, mode='train'):\n",
    "        posgen = native_gen(mode=mode)\n",
    "        if prediction_window % scrambled != 0:\n",
    "            print(str(scrambled) + 'mers do not evenly divide the sequence.')\n",
    "            scrambled = 1\n",
    "        for p, q in posgen:\n",
    "            p = np.asarray([base for base in p])\n",
    "            p = p.reshape((-1,scrambled))\n",
    "            np.random.shuffle(p)\n",
    "            p = p.reshape([-1])\n",
    "            yield ''.join(p) \n",
    "            \n",
    "            \n",
    "def pair_gen(mode='train', once=False, batch_size=32):\n",
    "    \"\"\"Generate batched of paired samples.\"\"\"\n",
    "    p = native_gen(mode=mode, once=once)\n",
    "    n = scrambled_gen(2, mode=mode)\n",
    "    while True:\n",
    "        pos_seqs = list()\n",
    "        neg_seqs = list()\n",
    "        scores = list()\n",
    "        for i in range(batch_size // 2):\n",
    "            pos_seq, score = next(p)\n",
    "            neg_seq = next(n)\n",
    "            pos_seqs.append(sequence.encode_to_onehot(pos_seq))\n",
    "            neg_seqs.append(sequence.encode_to_onehot(neg_seq))\n",
    "            scores.append(score)\n",
    "        labels = np.append(np.asarray(scores), np.zeros((32 // 2, len(scores[0]))), axis=0)\n",
    "        yield np.asarray(pos_seqs + neg_seqs), labels"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Define the model: \n",
    "\n",
    "A one hot input with reverse complement -- > series of convolutions --> smoothing --> maximum over directions --> bias --> activation\n",
    "\n",
    "Input *is* one hot encoded - and type np.uint8.\n",
    "add reverse complement so the model only has to learn one direciton\n",
    "output an acitvaiton at each base form convolutions of convolutions\n",
    "Take wide-window convolution scan with fixed wieghts to smooth out peaks.\n",
    "Get the forward/reverse sequence maximum. \n",
    "Add a custom bias layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sys.path.append('/home/thouis/basenji_embeddings')\n",
    "from zinb import ZINB\n",
    "\n",
    "# layers\n",
    "input = Input(batch_shape=(batch_size, prediction_window, 4))\n",
    "add_RC_to_batch = Lambda(lambda x: K.concatenate([x, x[:, ::-1, ::-1]], axis=0), output_shape=lambda s: (2 * s[0], s[1], s[2]))\n",
    "per_base_score = train_TFmodel.BasicConv(prediction_window, conv_list, final_activation=None, num_outputs=num_outputs, drop_rate=drop_rate)(add_RC_to_batch(input))\n",
    "wide_scan = Conv1D(num_outputs, 50, use_bias=False, kernel_initializer='ones', trainable=False, name='wide_scan', padding='valid')\n",
    "max_by_direction = Lambda(lambda x: K.maximum(K.max(x[:x.shape[0]//2, :, :], axis=1), K.max(x[x.shape[0]//2:, ::-1, :], axis=1)), name='stackmax', output_shape=lambda s: (s[0] // 2, num_outputs))\n",
    "predictions = train_TFmodel.Bias(num_outputs, name='bias')(max_by_direction(wide_scan(per_base_score)))\n",
    "\n",
    "# build the model\n",
    "model = Model(inputs=[input], outputs=[predictions])\n",
    "\n",
    "#zinb stuff\n",
    "pi_layer = Dense(num_outputs, activation='sigmoid')\n",
    "\n",
    "pi = max_by_direction(pi_layer(add_RC_to_batch(input)))       # not sure what layer to put here\n",
    "\n",
    "\n",
    "zinb = ZINB(pi, theta_init=tf.zeros([1, num_outputs]))\n",
    "model.layers[-1].trainable_weights.extend([zinb.theta_variable,\n",
    "                                           *pi_layer.trainable_weights])\n",
    "\n",
    "# save a graph of the model configuration\n",
    "#plot_model(model, to_file=os.path.join(out_path, conv_string + '_model.png'), show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# train the model\n",
    "num_batches = len(peaks[peaks.chr != 'chr8']) // batch_size\n",
    "print(str(num_batches) + ' batches')\n",
    "val_steps = len(peaks[peaks.chr == 'chr8']) // (batch_size * 2)\n",
    "verb=1\n",
    "\n",
    "opt = Adam(beta_1=0.95, lr=1e-5, epsilon=.1)\n",
    "opt = RMSprop(lr=1e-6)\n",
    "model.compile(optimizer=opt,\n",
    "              loss=zinb.loss)  # zinb loss function\n",
    "\n",
    "checkpath = os.path.join(weights_path, '_'.join(['weights_{epoch:02d}_{val_loss:.2f}.hdf5']))\n",
    "checkpoint = ModelCheckpoint(checkpath, verbose=verb, monitor='val_loss', mode='min')\n",
    "\n",
    "#history = model.fit_generator(pair_gen(), steps_per_epoch=num_batches/(batch_size), epochs=200,\n",
    "#                   callbacks=[checkpoint], validation_data=pair_gen(mode='val'), \n",
    "#                   validation_steps=val_steps, verbose=2)\n",
    "        \n",
    "history = model.fit_generator(pair_gen(), steps_per_epoch=2, epochs=200,\n",
    "                   callbacks=[checkpoint], validation_data=pair_gen(mode='val'), \n",
    "                   validation_steps=2, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
